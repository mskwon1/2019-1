# Beyond Physical Memory
## Memory Hierarchy
- Memory : 빠르지만 작음
- Disk : 느리지만 큼
- OS는 여러 프로세스를 동시에 실행시키길 원함
  -> 자주 접근한 데이터 : 메모리에 위치
  -> 가끔 접근한 데이터 : 디스크에 위치, 필요할때 메모리로 불러옴
## Swap Space
- 디스크 안에서 페이지를 앞뒤로 움직이는 공간
- 프로세서를 위해 물리 메모리보다 큰 가상 메모리를 지원
- 프로그래머에게 보이지 않음
## Present Bit / Page Fault
- 해당 페이지가 메모리 안에 있는지 swap out 됐는지 확인 하는 법
- Present Bit가 1 이면 페이지 접근, 0이면 페이지 폴트 발생(디스크에서 가져와야 함)
- segmentation fault는 그냥 오류, page fault는 일부러 만들어 놓은 개념
## Memory가 가득 찼을 때
- 하나 이상의 페이지를 없앰(faulted page를 위한 공간)
- 무슨 페이지를 없앨것인지는 Replacement policy를 따름
  -> 틀린 선택 = page fault 증가
  -> 디스크의 속도 이용(메모리 스피드 아님)
  -> replacement policy : 매우 중요함
## Replacement
- OS가 사전에 free 메모리를 준비, 메모리가 가득찰떄까지 안기다림
- page 몇개를 그룹화하고, 한번에 다 씀(순차 쓰기의 성능 상승)
## Policies
- On-demand loading : 로딩 하기준에 정보를 매핑한다(빠른 실행)
  : 실행 시작 -> page fault 발생 -> lazy manner로 로딩 시작(실제로 사용되는 페이지들)
  : 프레임이 많은 경우에 쉬워짐
- 조금의 메모리만 free인 경우 : Memory Pressure가 OS를 paging out해서 공간을 만들도록 강제
  -> Replacement policy : 어떤 페이지를 쫓아낼지 결정
### Cache Management
- 목표 : cache hit 비율을 최대화하고, cache miss 비율을 최소화
- Model : Average Memory Access Time(AMAT) = P_Hit*T_M + P_Miss*T_D
  -> T_M = 메모리 접근 latency, T_D = 디스크 접근 latency, P_miss = 1- P_hit(확률)
    -> Hit 비율은 중요함(기대값 = S_M/S_D ... 접근 패턴이 균일분포일 때)
      locality가 실현 가능하게 함
### Optimal Replacement Policy(MIN)
- 미래에 가장 나중에 접근 할 페이지를 쫓아냄
  -> 최고의 시나리오지만, 구현 불가능함(비교용으로만 존재)
### FIFO Policy
- 먼저 온 페이지를 쫓아냄
- 간단하지만, locality를 고려하지 않았으며 프레임의 수가 증가하면 히트확률이 줄어들 수 있음(Belady's Anomaly)
### Random Policy
- 랜덤으로 선택해서 쫓아냄
- 간단하지만, locality를 고려하지 않았고 예측불가능함
### LRU(Least Recently Used)
- 과거에 가장 오래전에 접근 한 페이지를 쫓아냄
- temporal locality를 고려했음
- looping reference를 할 시 안 좋음
- History-based(과거이력을 사용함) ex) LRU,LFU,LRFU ...
### Workload Examples
- locality가 없는 데이터의 경우 -> LRU = FIFO = RAND
- 80-20(hot-cold) 데이터의 경우 -> LRU > FIFO = RAND
- Loop workload 데이터의 경우 -> LRU = FIFO < RAND
- 대부분의 프로그램은 강한 locality를 보임 -> LRU가 자주 쓰임
- 캐시가 커지면 optimal에 가까워짐
### LRU Implementation
- 주로 링크드 리스트 사용
- 페이지 접근 : 리스트의 HEAD에(MRU) 삽입, 나머지 페이지들은 모두 밑으로 이동, LRU에 있는 페이지 삭제(필요 시)
- 모든 메모리접근을 감시해야함
  -> 파일 캐시, 서버 캐시에는 실현 가능
  -> 메모리 캐시에는 성능저하 가능성 -> 하드웨어에서 레퍼런스 비트, 더티 비트를 사용해 지원
### LRU Approxiamtion
- Clock 알고리즘 : 레퍼런스 비트가 있는 FIFO
  -> 하드웨어 : 페이지가 접근 됐을 경우 레퍼런스 비트를 1로 set
  -> 운영체제 : 다음 페이지를 찾아서 검증(레퍼런스비트가 1이면 0으로 바꾸고, 0이면 쫓아냄)
- Advanced Version : Periodic Clearing, reference/dirty bit 둘다 사용하기
### Dirty Pages / VM Policies
- Dirty Bit : 페이지가 수정 됐는지를 표시
  -> 지연된 쓰기를 위해 사용 ... 이 페이지는 걷어내는데에 더 많은 작업량 필요
  -> replacement에 이용 할 수 있음 (Reference, Dirty)
      쫓아내는 선호도 : (0,0) > (0,1) > (1,0) > (1,1) -> dirty 페이지는 두번째 찬스를 줌
